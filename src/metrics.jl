module Metrics

export metric_dict, is_maximise, get_metric

import Statistics: mean, std
import NNlib: logsigmoid, logsoftmax, softmax, relu, hardsigmoid
using Lux
using Lux: Training
using Reactant

"""
    mse(m, x, y; agg=mean)
    mse(m, x, y, w; agg=mean)
    mse(m, x, y, w, offset; agg=mean)
"""
function mse(m, x, y; agg=mean)
    return agg((vec(m(x)) .- vec(y)) .^ 2)
end
function mse(m, x, y, w; agg=mean)
    return agg((vec(m(x)) .- vec(y)) .^ 2 .* vec(w))
end
function mse(m, x, y, w, offset; agg=mean)
    return agg((vec(m(x)) .+ vec(offset) .- vec(y)) .^ 2 .* vec(w))
end

"""
    mae(m, x, y; agg=mean)
    mae(m, x, y, w; agg=mean)
    mae(m, x, y, w, offset; agg=mean)
"""
function mae(m, x, y; agg=mean)
    return agg(abs.(vec(m(x)) .- vec(y)))
end
function mae(m, x, y, w; agg=mean)
    return agg(abs.(vec(m(x)) .- vec(y)) .* vec(w))
end
function mae(m, x, y, w, offset; agg=mean)
    return agg(abs.(vec(m(x)) .+ vec(offset) .- vec(y)) .* vec(w))
end


"""
    logloss(m, x, y; agg=mean)
    logloss(m, x, y, w; agg=mean)
    logloss(m, x, y, w, offset; agg=mean)
"""
function logloss(m, x, y; agg=mean)
    p = vec(m(x))
    y = vec(y)
    return agg((1 .- y) .* p .- logsigmoid.(p))
end
function logloss(m, x, y, w; agg=mean)
    p = vec(m(x))
    y = vec(y)
    return agg(((1 .- y) .* p .- logsigmoid.(p)) .* vec(w))
end
function logloss(m, x, y, w, offset; agg=mean)
    p = vec(m(x)) .+ vec(offset)
    y = vec(y)
    return agg(((1 .- y) .* p .- logsigmoid.(p)) .* vec(w))
end


"""
    tweedie(m, x, y; agg=mean)
    tweedie(m, x, y, w; agg=mean)
    tweedie(m, x, y, w, offset; agg=mean)
"""
function tweedie(m, x, y; agg=mean)
    rho = eltype(x)(1.5)
    p = exp.(vec(m(x)))
    y = vec(y)
    return agg(2 .* (y .^ (2 - rho) / (1 - rho) / (2 - rho) - y .* p .^ (1 - rho) / (1 - rho) +
                     p .^ (2 - rho) / (2 - rho)))
end
function tweedie(m, x, y, w; agg=mean)
    rho = eltype(x)(1.5)
    p = exp.(vec(m(x)))
    y = vec(y)
    w = vec(w)
    return agg(w .* 2 .* (y .^ (2 - rho) / (1 - rho) / (2 - rho) - y .* p .^ (1 - rho) / (1 - rho) +
                          p .^ (2 - rho) / (2 - rho)))
end
function tweedie(m, x, y, w, offset; agg=mean)
    rho = eltype(x)(1.5)
    p = exp.(vec(m(x)) .+ vec(offset))
    y = vec(y)
    w = vec(w)
    return agg(w .* 2 .* (y .^ (2 - rho) / (1 - rho) / (2 - rho) - y .* p .^ (1 - rho) / (1 - rho) +
                          p .^ (2 - rho) / (2 - rho)))
end

"""
    mlogloss(m, x, y; agg=mean)
    mlogloss(m, x, y, w; agg=mean)
    mlogloss(m, x, y, w, offset; agg=mean)
"""
function mlogloss(m, x, y; agg=mean)
    p = m(x)                                                 # (k, batch)
    k = size(p, 1)
    y_oh = (UInt32(1):UInt32(k)) .== reshape(y, 1, :)       # (k, batch)
    lsm = logsoftmax(p; dims=1)
    return agg(vec(-sum(y_oh .* lsm; dims=1)))
end
function mlogloss(m, x, y, w; agg=mean)
    p = m(x)
    k = size(p, 1)
    y_oh = (UInt32(1):UInt32(k)) .== reshape(y, 1, :)
    lsm = logsoftmax(p; dims=1)
    return agg(vec(-sum(y_oh .* lsm; dims=1)) .* vec(w))
end
function mlogloss(m, x, y, w, offset; agg=mean)
    p = m(x) .+ offset
    k = size(p, 1)
    y_oh = (UInt32(1):UInt32(k)) .== reshape(y, 1, :)
    lsm = logsoftmax(p; dims=1)
    return agg(vec(-sum(y_oh .* lsm; dims=1)) .* vec(w))
end


gaussian_loss_elt(μ, σ, y) = -σ - (y - μ)^2 / (2 * max(2.0f-7, exp(2 * σ)))


"""
    gaussian_mle(m, x, y; agg=mean)
    gaussian_mle(m, x, y, w; agg=mean)
    gaussian_mle(m, x, y, w, offset; agg=mean)
"""
function gaussian_mle(m, x, y; agg=mean)
    p = m(x)
    μ = view(p, :, 1)
    σ = view(p, :, 2)
    return agg(gaussian_loss_elt.(μ, σ, vec(y)))
end
function gaussian_mle(m, x, y, w; agg=mean)
    p = m(x)
    μ = view(p, :, 1)
    σ = view(p, :, 2)
    return agg(gaussian_loss_elt.(μ, σ, vec(y)) .* vec(w))
end
function gaussian_mle(m, x, y, w, offset; agg=mean)
    p = m(x) .+ offset
    μ = view(p, :, 1)
    σ = view(p, :, 2)
    return agg(gaussian_loss_elt.(μ, σ, vec(y)) .* vec(w))
end

function get_metric(ts::Training.TrainState, data, eval_compiled)
    ps, st = ts.parameters, Lux.testmode(ts.states)

    metric_accum = nothing
    ws_accum = nothing
    
    for d in data
        m_val, w_val = eval_compiled(d..., ps, st)
        
        if isnothing(metric_accum)
            metric_accum = m_val
            ws_accum = w_val
        else
            metric_accum = metric_accum .+ m_val
            ws_accum = ws_accum .+ w_val
        end
    end
    
    # helper to safely move to CPU only if it's a Reactant GPU object
    to_cpu(x) = x isa Reactant.ConcretePJRTNumber || x isa Reactant.ConcretePJRTArray ? first(Array(x)) : x

    final_metric = Float32(to_cpu(metric_accum))
    final_ws = Float32(to_cpu(ws_accum))
    
    return final_metric / final_ws
end
const metric_dict = Dict(
    :mse => mse,
    :mae => mae,
    :logloss => logloss,
    :mlogloss => mlogloss,
    :gaussian_mle => gaussian_mle,
    :tweedie => tweedie,
)

is_maximise(::typeof(mse)) = false
is_maximise(::typeof(mae)) = false
is_maximise(::typeof(logloss)) = false
is_maximise(::typeof(mlogloss)) = false
is_maximise(::typeof(gaussian_mle)) = true
is_maximise(::typeof(tweedie)) = false

end